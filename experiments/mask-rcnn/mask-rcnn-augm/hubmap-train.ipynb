{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:50.158863Z",
     "iopub.status.busy": "2023-07-11T20:55:50.158344Z",
     "iopub.status.idle": "2023-07-11T20:55:50.649519Z",
     "shell.execute_reply": "2023-07-11T20:55:50.649187Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(\"detection-wheel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:50.651038Z",
     "iopub.status.busy": "2023-07-11T20:55:50.650891Z",
     "iopub.status.idle": "2023-07-11T20:55:50.652551Z",
     "shell.execute_reply": "2023-07-11T20:55:50.652375Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:50.653765Z",
     "iopub.status.busy": "2023-07-11T20:55:50.653677Z",
     "iopub.status.idle": "2023-07-11T20:55:51.175336Z",
     "shell.execute_reply": "2023-07-11T20:55:51.175011Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, masks, mode):\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = imgs#sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/image/*.png'))\n",
    "        self.masks = masks#sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/mask/*.png'))\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        init_augm = []\n",
    "        if mode == 'train':\n",
    "            init_augm = [\n",
    "                A.HorizontalFlip(p=0.25),\n",
    "                A.VerticalFlip(p=0.25),\n",
    "                A.Transpose(p=0.25),\n",
    "                # A.GridDistortion(p=0.25),\n",
    "                # A.RandomSizedCrop(min_max_height=(int(512 * 0.8), int(512 * 0.9)),\n",
    "                #                     height=512, width=512, p=0.25),\n",
    "                \n",
    "                \n",
    "                A.CLAHE(p=0.2),\n",
    "                A.RandomBrightnessContrast(p=0.2),    \n",
    "                A.RandomGamma(p=0.2),\n",
    "                \n",
    "                A.OneOf([\n",
    "                        A.GaussNoise(var_limit=[10, 50]),\n",
    "                        A.GaussianBlur(),\n",
    "                        A.MotionBlur(),\n",
    "                        ], p=0.1),\n",
    "                A.MultiplicativeNoise(per_channel=True, multiplier=(0.95, 1.05), p=0.2),\n",
    "            ]\n",
    "        \n",
    "        self.transform = A.Compose(\n",
    "            init_augm+[ToTensorV2()], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        mask_path = self.masks[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        # convert the PIL Image into a numpy array\n",
    "        mask = np.array(mask)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        #masks = (mask == obj_ids[:, None, None])\n",
    "        #print((obj_ids[:, None, None]).shape)\n",
    "        #masks = mask == obj_ids[:, None, None]\n",
    "        masks = [np.where(mask== obj_ids[i, None, None],1,0) for i in range(len(obj_ids))]\n",
    "        masks = np.array(masks)\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        bboxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.nonzero(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            bboxes.append([xmin, ymin, xmax, ymax, 0])\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        \n",
    "        transformed = self.transform(image=img, bboxes=bboxes)\n",
    "        img = transformed['image'].float() / 255.0\n",
    "        boxes = transformed['bboxes']\n",
    "        boxes = []\n",
    "        # get xmin, ymin, xmax, ymax from bboxes\n",
    "        for i in range(len(transformed['bboxes'])):\n",
    "            boxes.append(transformed['bboxes'][i][:4])\n",
    "\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        try:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "            #print(area,area.shape,area.dtype)\n",
    "        except:\n",
    "            area = torch.tensor([[0],[0]])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        #print(masks.shape)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        # if self.transforms is not None:\n",
    "        #     img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.176860Z",
     "iopub.status.busy": "2023-07-11T20:55:51.176708Z",
     "iopub.status.idle": "2023-07-11T20:55:51.228454Z",
     "shell.execute_reply": "2023-07-11T20:55:51.228169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasterrcnn_mobilenet_v3_large_320_fpn',\n",
       " 'fasterrcnn_mobilenet_v3_large_fpn',\n",
       " 'fasterrcnn_resnet50_fpn',\n",
       " 'fasterrcnn_resnet50_fpn_v2',\n",
       " 'fcos_resnet50_fpn',\n",
       " 'keypointrcnn_resnet50_fpn',\n",
       " 'maskrcnn_resnet50_fpn',\n",
       " 'maskrcnn_resnet50_fpn_v2',\n",
       " 'retinanet_resnet50_fpn',\n",
       " 'retinanet_resnet50_fpn_v2',\n",
       " 'ssd300_vgg16',\n",
       " 'ssdlite320_mobilenet_v3_large']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models import list_models\n",
    "detection_models = list_models(module=torchvision.models.detection)\n",
    "detection_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.243653Z",
     "iopub.status.busy": "2023-07-11T20:55:51.243517Z",
     "iopub.status.idle": "2023-07-11T20:55:51.245790Z",
     "shell.execute_reply": "2023-07-11T20:55:51.245599Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=\"DEFAULT\", weights_backbone=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.250040Z",
     "iopub.status.busy": "2023-07-11T20:55:51.249919Z",
     "iopub.status.idle": "2023-07-11T20:55:51.252379Z",
     "shell.execute_reply": "2023-07-11T20:55:51.252197Z"
    }
   },
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.253503Z",
     "iopub.status.busy": "2023-07-11T20:55:51.253387Z",
     "iopub.status.idle": "2023-07-11T20:55:51.262727Z",
     "shell.execute_reply": "2023-07-11T20:55:51.262523Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.263931Z",
     "iopub.status.busy": "2023-07-11T20:55:51.263788Z",
     "iopub.status.idle": "2023-07-11T20:55:51.266884Z",
     "shell.execute_reply": "2023-07-11T20:55:51.266711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_imgs = len(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/image/*'))\n",
    "n_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/image/*.png'))\n",
    "all_masks = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/mask/*.png'))\n",
    "dataset_train = PennFudanDataset(all_imgs, all_masks, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 512]), tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset_train[0][0]\n",
    "x.shape, x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.268015Z",
     "iopub.status.busy": "2023-07-11T20:55:51.267921Z",
     "iopub.status.idle": "2023-07-11T20:55:51.269472Z",
     "shell.execute_reply": "2023-07-11T20:55:51.269301Z"
    }
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=43)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(range(n_imgs))):\n",
    "#     if i!=0: continue\n",
    "#     all_imgs = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/image/*.png'))\n",
    "#     all_masks = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/mask/*.png'))\n",
    "#     all_imgs = np.array(all_imgs)\n",
    "#     all_masks = np.array(all_masks)\n",
    "#     train_img = all_imgs[train_index]\n",
    "#     train_mask = all_masks[train_index]\n",
    "#     val_img = all_imgs[test_index]\n",
    "#     val_mask = all_masks[test_index]\n",
    "#     dataset_train = PennFudanDataset(train_img, train_mask, get_transform(train=True))\n",
    "#     dataset_val = PennFudanDataset(val_img, val_mask, get_transform(train=False))\n",
    "#     train_dl = torch.utils.data.DataLoader(\n",
    "#         dataset_train, batch_size=4, shuffle=True, num_workers=os.cpu_count(), pin_memory=True, drop_last=True, collate_fn=utils.collate_fn)\n",
    "#     val_dl = torch.utils.data.DataLoader(\n",
    "#         dataset_val, batch_size=1, shuffle=False, num_workers=os.cpu_count(), pin_memory=True,collate_fn=utils.collate_fn)\n",
    "    \n",
    "#     model = get_model_instance_segmentation(num_classes=2)\n",
    "#     model.to(device)\n",
    "#     params = [p for p in model.parameters() if p.requires_grad]\n",
    "#     optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=1e-6)\n",
    "#     # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "#     # set linear warmup scheduler, with constant learning rate after warmup\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0001,\n",
    "#                                                 steps_per_epoch=10, epochs=EPOCHS//10,\n",
    "#                                                 pct_start=0.01)\n",
    "    \n",
    "#     for epoch in range(EPOCHS):\n",
    "#         train_one_epoch(model, optimizer, train_dl, device, epoch, print_freq=50)\n",
    "#         evaluate(model, val_dl, device=device)\n",
    "#         scheduler.step()\n",
    "#         model_path = f'fold_{i}_epoch{epoch}.pth'\n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.270596Z",
     "iopub.status.busy": "2023-07-11T20:55:51.270487Z",
     "iopub.status.idle": "2023-07-11T20:55:51.272248Z",
     "shell.execute_reply": "2023-07-11T20:55:51.272071Z"
    }
   },
   "outputs": [],
   "source": [
    "all_indices = np.arange(n_imgs)\n",
    "# take random 1400 images for training\n",
    "train_index = np.random.choice(all_indices, size=1400, replace=False)\n",
    "# take the rest for validation\n",
    "test_index = np.setdiff1d(all_indices, train_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.273372Z",
     "iopub.status.busy": "2023-07-11T20:55:51.273257Z",
     "iopub.status.idle": "2023-07-11T20:55:51.274962Z",
     "shell.execute_reply": "2023-07-11T20:55:51.274789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if train_index and test_index are mutually exclusive\n",
    "len(np.intersect1d(train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T20:55:51.275939Z",
     "iopub.status.busy": "2023-07-11T20:55:51.275834Z",
     "iopub.status.idle": "2023-07-12T00:21:56.837704Z",
     "shell.execute_reply": "2023-07-12T00:21:56.837259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/350]  eta: 0:14:23  lr: 0.000000  loss: 2.9118 (2.9118)  loss_classifier: 0.7202 (0.7202)  loss_box_reg: 0.1259 (0.1259)  loss_mask: 1.4431 (1.4431)  loss_objectness: 0.5804 (0.5804)  loss_rpn_box_reg: 0.0422 (0.0422)  time: 2.4660  data: 1.1636  max mem: 5151\n",
      "Epoch: [0]  [ 50/350]  eta: 0:01:06  lr: 0.000001  loss: 3.5595 (3.4909)  loss_classifier: 0.6408 (0.6796)  loss_box_reg: 0.1029 (0.1244)  loss_mask: 1.6903 (1.6009)  loss_objectness: 0.9440 (0.9817)  loss_rpn_box_reg: 0.1175 (0.1043)  time: 0.1736  data: 0.0001  max mem: 5851\n",
      "Epoch: [0]  [100/350]  eta: 0:00:49  lr: 0.000001  loss: 2.7691 (3.2410)  loss_classifier: 0.4172 (0.5828)  loss_box_reg: 0.1112 (0.1197)  loss_mask: 1.2666 (1.5127)  loss_objectness: 0.8648 (0.9220)  loss_rpn_box_reg: 0.0911 (0.1038)  time: 0.1732  data: 0.0001  max mem: 5953\n",
      "Epoch: [0]  [150/350]  eta: 0:00:37  lr: 0.000002  loss: 2.6284 (3.0689)  loss_classifier: 0.2607 (0.4878)  loss_box_reg: 0.1329 (0.1244)  loss_mask: 1.2349 (1.4449)  loss_objectness: 0.8030 (0.9064)  loss_rpn_box_reg: 0.0850 (0.1054)  time: 0.1757  data: 0.0001  max mem: 6030\n",
      "Epoch: [0]  [200/350]  eta: 0:00:27  lr: 0.000002  loss: 2.1438 (2.8791)  loss_classifier: 0.2086 (0.4213)  loss_box_reg: 0.1488 (0.1303)  loss_mask: 0.9720 (1.3440)  loss_objectness: 0.7856 (0.8784)  loss_rpn_box_reg: 0.0758 (0.1051)  time: 0.1757  data: 0.0005  max mem: 6030\n",
      "Epoch: [0]  [250/350]  eta: 0:00:18  lr: 0.000003  loss: 1.7506 (2.6790)  loss_classifier: 0.1918 (0.3770)  loss_box_reg: 0.1585 (0.1355)  loss_mask: 0.8177 (1.2477)  loss_objectness: 0.4895 (0.8170)  loss_rpn_box_reg: 0.0670 (0.1019)  time: 0.1738  data: 0.0001  max mem: 6030\n",
      "Epoch: [0]  [300/350]  eta: 0:00:09  lr: 0.000003  loss: 1.6492 (2.5199)  loss_classifier: 0.2125 (0.3490)  loss_box_reg: 0.2020 (0.1433)  loss_mask: 0.7847 (1.1711)  loss_objectness: 0.3364 (0.7584)  loss_rpn_box_reg: 0.0731 (0.0982)  time: 0.1767  data: 0.0001  max mem: 6083\n",
      "Epoch: [0]  [349/350]  eta: 0:00:00  lr: 0.000004  loss: 1.5484 (2.4007)  loss_classifier: 0.2255 (0.3322)  loss_box_reg: 0.2139 (0.1544)  loss_mask: 0.7118 (1.1088)  loss_objectness: 0.3179 (0.7080)  loss_rpn_box_reg: 0.0600 (0.0972)  time: 0.1756  data: 0.0001  max mem: 6191\n",
      "Epoch: [0] Total time: 0:01:03 (0.1817 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/222]  eta: 0:03:14  model_time: 0.1196 (0.1196)  evaluator_time: 0.0392 (0.0392)  time: 0.8742  data: 0.7150  max mem: 6191\n",
      "Test:  [100/222]  eta: 0:00:13  model_time: 0.0572 (0.0578)  evaluator_time: 0.0391 (0.0402)  time: 0.0989  data: 0.0001  max mem: 6191\n",
      "Test:  [200/222]  eta: 0:00:02  model_time: 0.0563 (0.0574)  evaluator_time: 0.0398 (0.0406)  time: 0.0992  data: 0.0001  max mem: 6191\n",
      "Test:  [221/222]  eta: 0:00:00  model_time: 0.0562 (0.0573)  evaluator_time: 0.0394 (0.0405)  time: 0.0976  data: 0.0001  max mem: 6191\n",
      "Test: Total time: 0:00:22 (0.1032 s / it)\n",
      "Averaged stats: model_time: 0.0562 (0.0573)  evaluator_time: 0.0394 (0.0405)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      "Epoch: [1]  [  0/350]  eta: 0:08:30  lr: 0.000100  loss: 1.5108 (1.5108)  loss_classifier: 0.2378 (0.2378)  loss_box_reg: 0.2373 (0.2373)  loss_mask: 0.6267 (0.6267)  loss_objectness: 0.3424 (0.3424)  loss_rpn_box_reg: 0.0666 (0.0666)  time: 1.4576  data: 1.2673  max mem: 6191\n",
      "Epoch: [1]  [ 50/350]  eta: 0:01:03  lr: 0.000100  loss: 1.2334 (1.4244)  loss_classifier: 0.2127 (0.2388)  loss_box_reg: 0.2831 (0.3010)  loss_mask: 0.5387 (0.6288)  loss_objectness: 0.1303 (0.1868)  loss_rpn_box_reg: 0.0443 (0.0689)  time: 0.1875  data: 0.0002  max mem: 6546\n",
      "Epoch: [1]  [100/350]  eta: 0:00:50  lr: 0.000100  loss: 1.2136 (1.3626)  loss_classifier: 0.2262 (0.2383)  loss_box_reg: 0.3162 (0.3171)  loss_mask: 0.5625 (0.5825)  loss_objectness: 0.1196 (0.1619)  loss_rpn_box_reg: 0.0428 (0.0628)  time: 0.1918  data: 0.0001  max mem: 6839\n",
      "Epoch: [1]  [150/350]  eta: 0:00:39  lr: 0.000100  loss: 1.2412 (1.3143)  loss_classifier: 0.2264 (0.2346)  loss_box_reg: 0.3316 (0.3178)  loss_mask: 0.5124 (0.5586)  loss_objectness: 0.0974 (0.1449)  loss_rpn_box_reg: 0.0406 (0.0584)  time: 0.1912  data: 0.0001  max mem: 6839\n",
      "Epoch: [1]  [200/350]  eta: 0:00:29  lr: 0.000100  loss: 1.1465 (1.2829)  loss_classifier: 0.2193 (0.2314)  loss_box_reg: 0.3082 (0.3182)  loss_mask: 0.4682 (0.5456)  loss_objectness: 0.0929 (0.1333)  loss_rpn_box_reg: 0.0377 (0.0545)  time: 0.1913  data: 0.0001  max mem: 6839\n",
      "Epoch: [1]  [250/350]  eta: 0:00:19  lr: 0.000100  loss: 1.2032 (1.2646)  loss_classifier: 0.2250 (0.2295)  loss_box_reg: 0.3096 (0.3183)  loss_mask: 0.4904 (0.5346)  loss_objectness: 0.0940 (0.1279)  loss_rpn_box_reg: 0.0436 (0.0542)  time: 0.1910  data: 0.0001  max mem: 6910\n",
      "Epoch: [1]  [300/350]  eta: 0:00:09  lr: 0.000100  loss: 1.0569 (1.2600)  loss_classifier: 0.2327 (0.2317)  loss_box_reg: 0.3269 (0.3216)  loss_mask: 0.3768 (0.5279)  loss_objectness: 0.0911 (0.1250)  loss_rpn_box_reg: 0.0425 (0.0538)  time: 0.1917  data: 0.0001  max mem: 7073\n",
      "Epoch: [1]  [349/350]  eta: 0:00:00  lr: 0.000100  loss: 1.1267 (1.2478)  loss_classifier: 0.2274 (0.2314)  loss_box_reg: 0.3185 (0.3210)  loss_mask: 0.4569 (0.5220)  loss_objectness: 0.0734 (0.1206)  loss_rpn_box_reg: 0.0365 (0.0527)  time: 0.1904  data: 0.0001  max mem: 7112\n",
      "Epoch: [1] Total time: 0:01:08 (0.1947 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/222]  eta: 0:03:08  model_time: 0.0457 (0.0457)  evaluator_time: 0.0131 (0.0131)  time: 0.8513  data: 0.7922  max mem: 7112\n",
      "Test:  [100/222]  eta: 0:00:09  model_time: 0.0362 (0.0377)  evaluator_time: 0.0348 (0.0321)  time: 0.0732  data: 0.0001  max mem: 7112\n",
      "Test:  [200/222]  eta: 0:00:01  model_time: 0.0381 (0.0391)  evaluator_time: 0.0345 (0.0329)  time: 0.0774  data: 0.0001  max mem: 7112\n",
      "Test:  [221/222]  eta: 0:00:00  model_time: 0.0381 (0.0394)  evaluator_time: 0.0345 (0.0328)  time: 0.0764  data: 0.0001  max mem: 7112\n",
      "Test: Total time: 0:00:17 (0.0769 s / it)\n",
      "Averaged stats: model_time: 0.0381 (0.0394)  evaluator_time: 0.0345 (0.0328)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.566\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
      "Epoch: [2]  [  0/350]  eta: 0:08:17  lr: 0.000100  loss: 1.1785 (1.1785)  loss_classifier: 0.1690 (0.1690)  loss_box_reg: 0.3044 (0.3044)  loss_mask: 0.6173 (0.6173)  loss_objectness: 0.0486 (0.0486)  loss_rpn_box_reg: 0.0392 (0.0392)  time: 1.4204  data: 1.2102  max mem: 7112\n",
      "Epoch: [2]  [ 50/350]  eta: 0:01:05  lr: 0.000100  loss: 1.0083 (1.1059)  loss_classifier: 0.1985 (0.2210)  loss_box_reg: 0.2761 (0.3205)  loss_mask: 0.3697 (0.4349)  loss_objectness: 0.0637 (0.0865)  loss_rpn_box_reg: 0.0327 (0.0430)  time: 0.1915  data: 0.0001  max mem: 7112\n",
      "Epoch: [2]  [100/350]  eta: 0:00:51  lr: 0.000100  loss: 1.1009 (1.1317)  loss_classifier: 0.2235 (0.2267)  loss_box_reg: 0.3388 (0.3364)  loss_mask: 0.4659 (0.4506)  loss_objectness: 0.0569 (0.0783)  loss_rpn_box_reg: 0.0348 (0.0397)  time: 0.1940  data: 0.0001  max mem: 7112\n",
      "Epoch: [2]  [150/350]  eta: 0:00:40  lr: 0.000100  loss: 1.2588 (1.1458)  loss_classifier: 0.2003 (0.2256)  loss_box_reg: 0.3199 (0.3373)  loss_mask: 0.5137 (0.4605)  loss_objectness: 0.0726 (0.0801)  loss_rpn_box_reg: 0.0401 (0.0423)  time: 0.1948  data: 0.0001  max mem: 7112\n",
      "Epoch: [2]  [200/350]  eta: 0:00:30  lr: 0.000100  loss: 1.0408 (1.1400)  loss_classifier: 0.2028 (0.2212)  loss_box_reg: 0.3140 (0.3336)  loss_mask: 0.4055 (0.4614)  loss_objectness: 0.0769 (0.0807)  loss_rpn_box_reg: 0.0434 (0.0430)  time: 0.1933  data: 0.0002  max mem: 7112\n",
      "Epoch: [2]  [250/350]  eta: 0:00:19  lr: 0.000100  loss: 1.0959 (1.1453)  loss_classifier: 0.2169 (0.2205)  loss_box_reg: 0.3690 (0.3350)  loss_mask: 0.4380 (0.4652)  loss_objectness: 0.0673 (0.0813)  loss_rpn_box_reg: 0.0397 (0.0433)  time: 0.1961  data: 0.0001  max mem: 7112\n",
      "Epoch: [2]  [300/350]  eta: 0:00:09  lr: 0.000100  loss: 1.0843 (1.1378)  loss_classifier: 0.2036 (0.2193)  loss_box_reg: 0.3158 (0.3331)  loss_mask: 0.4161 (0.4627)  loss_objectness: 0.0607 (0.0802)  loss_rpn_box_reg: 0.0400 (0.0424)  time: 0.1933  data: 0.0001  max mem: 7112\n",
      "Epoch: [2]  [349/350]  eta: 0:00:00  lr: 0.000100  loss: 1.1196 (1.1384)  loss_classifier: 0.1972 (0.2194)  loss_box_reg: 0.3168 (0.3332)  loss_mask: 0.4648 (0.4644)  loss_objectness: 0.0598 (0.0787)  loss_rpn_box_reg: 0.0374 (0.0427)  time: 0.1928  data: 0.0001  max mem: 7112\n",
      "Epoch: [2] Total time: 0:01:09 (0.1976 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/222]  eta: 0:03:24  model_time: 0.0387 (0.0387)  evaluator_time: 0.0085 (0.0085)  time: 0.9231  data: 0.8755  max mem: 7112\n",
      "Test:  [100/222]  eta: 0:00:07  model_time: 0.0289 (0.0310)  evaluator_time: 0.0240 (0.0256)  time: 0.0557  data: 0.0001  max mem: 7112\n",
      "Test:  [200/222]  eta: 0:00:01  model_time: 0.0297 (0.0307)  evaluator_time: 0.0259 (0.0260)  time: 0.0564  data: 0.0001  max mem: 7112\n",
      "Test:  [221/222]  eta: 0:00:00  model_time: 0.0300 (0.0307)  evaluator_time: 0.0275 (0.0259)  time: 0.0570  data: 0.0001  max mem: 7112\n",
      "Test: Total time: 0:00:13 (0.0613 s / it)\n",
      "Averaged stats: model_time: 0.0300 (0.0307)  evaluator_time: 0.0275 (0.0259)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.626\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342\n",
      "Epoch: [3]  [  0/350]  eta: 0:08:56  lr: 0.000100  loss: 1.1053 (1.1053)  loss_classifier: 0.2151 (0.2151)  loss_box_reg: 0.3353 (0.3353)  loss_mask: 0.4936 (0.4936)  loss_objectness: 0.0415 (0.0415)  loss_rpn_box_reg: 0.0198 (0.0198)  time: 1.5339  data: 1.3263  max mem: 7112\n",
      "Epoch: [3]  [ 50/350]  eta: 0:01:06  lr: 0.000100  loss: 1.0651 (1.1524)  loss_classifier: 0.2139 (0.2159)  loss_box_reg: 0.3426 (0.3462)  loss_mask: 0.4935 (0.4840)  loss_objectness: 0.0568 (0.0658)  loss_rpn_box_reg: 0.0316 (0.0405)  time: 0.1948  data: 0.0002  max mem: 7112\n",
      "Epoch: [3]  [100/350]  eta: 0:00:51  lr: 0.000100  loss: 1.0651 (1.1347)  loss_classifier: 0.2083 (0.2156)  loss_box_reg: 0.3402 (0.3350)  loss_mask: 0.4380 (0.4755)  loss_objectness: 0.0541 (0.0664)  loss_rpn_box_reg: 0.0314 (0.0422)  time: 0.1923  data: 0.0001  max mem: 7112\n",
      "Epoch: [3]  [150/350]  eta: 0:00:40  lr: 0.000100  loss: 1.0609 (1.1342)  loss_classifier: 0.2067 (0.2181)  loss_box_reg: 0.3160 (0.3365)  loss_mask: 0.4218 (0.4735)  loss_objectness: 0.0536 (0.0660)  loss_rpn_box_reg: 0.0318 (0.0402)  time: 0.1949  data: 0.0001  max mem: 7112\n",
      "Epoch: [3]  [200/350]  eta: 0:00:30  lr: 0.000100  loss: 1.1052 (1.1217)  loss_classifier: 0.1874 (0.2151)  loss_box_reg: 0.2823 (0.3288)  loss_mask: 0.4594 (0.4710)  loss_objectness: 0.0618 (0.0660)  loss_rpn_box_reg: 0.0453 (0.0408)  time: 0.1929  data: 0.0002  max mem: 7112\n",
      "Epoch: [3]  [250/350]  eta: 0:00:19  lr: 0.000100  loss: 1.0521 (1.1167)  loss_classifier: 0.1891 (0.2125)  loss_box_reg: 0.3201 (0.3285)  loss_mask: 0.4508 (0.4694)  loss_objectness: 0.0517 (0.0661)  loss_rpn_box_reg: 0.0284 (0.0402)  time: 0.1952  data: 0.0001  max mem: 7112\n",
      "Epoch: [3]  [300/350]  eta: 0:00:09  lr: 0.000100  loss: 1.1036 (1.1197)  loss_classifier: 0.1926 (0.2135)  loss_box_reg: 0.3161 (0.3320)  loss_mask: 0.4099 (0.4674)  loss_objectness: 0.0587 (0.0665)  loss_rpn_box_reg: 0.0388 (0.0403)  time: 0.1964  data: 0.0001  max mem: 7112\n",
      "Epoch: [3]  [349/350]  eta: 0:00:00  lr: 0.000100  loss: 1.1083 (1.1172)  loss_classifier: 0.1968 (0.2129)  loss_box_reg: 0.3032 (0.3304)  loss_mask: 0.4714 (0.4677)  loss_objectness: 0.0477 (0.0662)  loss_rpn_box_reg: 0.0351 (0.0401)  time: 0.1913  data: 0.0001  max mem: 7112\n",
      "Epoch: [3] Total time: 0:01:09 (0.1983 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [  0/222]  eta: 0:03:35  model_time: 0.0403 (0.0403)  evaluator_time: 0.0131 (0.0131)  time: 0.9721  data: 0.9181  max mem: 7112\n",
      "Test:  [100/222]  eta: 0:00:08  model_time: 0.0304 (0.0320)  evaluator_time: 0.0235 (0.0256)  time: 0.0591  data: 0.0001  max mem: 7112\n",
      "Test:  [200/222]  eta: 0:00:01  model_time: 0.0322 (0.0337)  evaluator_time: 0.0234 (0.0264)  time: 0.0643  data: 0.0001  max mem: 7112\n",
      "Test:  [221/222]  eta: 0:00:00  model_time: 0.0349 (0.0339)  evaluator_time: 0.0257 (0.0264)  time: 0.0629  data: 0.0001  max mem: 7112\n",
      "Test: Total time: 0:00:14 (0.0654 s / it)\n",
      "Averaged stats: model_time: 0.0349 (0.0339)  evaluator_time: 0.0257 (0.0264)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.596\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      "Epoch: [4]  [  0/350]  eta: 0:09:29  lr: 0.000100  loss: 1.2311 (1.2311)  loss_classifier: 0.2308 (0.2308)  loss_box_reg: 0.3620 (0.3620)  loss_mask: 0.5199 (0.5199)  loss_objectness: 0.0750 (0.0750)  loss_rpn_box_reg: 0.0432 (0.0432)  time: 1.6281  data: 1.4236  max mem: 7112\n",
      "Epoch: [4]  [ 50/350]  eta: 0:01:07  lr: 0.000100  loss: 1.0978 (1.0956)  loss_classifier: 0.1932 (0.2116)  loss_box_reg: 0.3219 (0.3340)  loss_mask: 0.4337 (0.4382)  loss_objectness: 0.0524 (0.0689)  loss_rpn_box_reg: 0.0362 (0.0429)  time: 0.1966  data: 0.0001  max mem: 7112\n",
      "Epoch: [4]  [100/350]  eta: 0:00:52  lr: 0.000100  loss: 1.0566 (1.0861)  loss_classifier: 0.1873 (0.2072)  loss_box_reg: 0.3133 (0.3277)  loss_mask: 0.4358 (0.4478)  loss_objectness: 0.0556 (0.0636)  loss_rpn_box_reg: 0.0312 (0.0397)  time: 0.1946  data: 0.0001  max mem: 7112\n",
      "Epoch: [4]  [150/350]  eta: 0:00:40  lr: 0.000100  loss: 1.0344 (1.0756)  loss_classifier: 0.2077 (0.2065)  loss_box_reg: 0.3262 (0.3226)  loss_mask: 0.4346 (0.4483)  loss_objectness: 0.0425 (0.0596)  loss_rpn_box_reg: 0.0297 (0.0385)  time: 0.1961  data: 0.0001  max mem: 7112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     22\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mOneCycleLR(optimizer, max_lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                             steps_per_epoch\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m     24\u001b[0m                                             pct_start\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 27\u001b[0m     train_one_epoch(model, optimizer, train_dl, device, epoch, print_freq\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m     evaluate(model, val_dl, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     29\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/mask-rcnn-augm/detection-wheel/engine.py:31\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[1;32m     29\u001b[0m targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n\u001b[1;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 31\u001b[0m     loss_dict \u001b[39m=\u001b[39m model(images, targets)\n\u001b[1;32m     32\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss \u001b[39mfor\u001b[39;00m loss \u001b[39min\u001b[39;00m loss_dict\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m     34\u001b[0m \u001b[39m# reduce losses over all GPUs for logging purposes\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torchvision/models/detection/generalized_rcnn.py:104\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(features, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    103\u001b[0m     features \u001b[39m=\u001b[39m OrderedDict([(\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m, features)])\n\u001b[0;32m--> 104\u001b[0m proposals, proposal_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrpn(images, features, targets)\n\u001b[1;32m    105\u001b[0m detections, detector_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroi_heads(features, proposals, images\u001b[39m.\u001b[39mimage_sizes, targets)\n\u001b[1;32m    106\u001b[0m detections \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mpostprocess(detections, images\u001b[39m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[39m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torchvision/models/detection/rpn.py:370\u001b[0m, in \u001b[0;36mRegionProposalNetwork.forward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    366\u001b[0m objectness, pred_bbox_deltas \u001b[39m=\u001b[39m concat_box_prediction_layers(objectness, pred_bbox_deltas)\n\u001b[1;32m    367\u001b[0m \u001b[39m# apply pred_bbox_deltas to anchors to obtain the decoded proposals\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m# note that we detach the deltas because Faster R-CNN do not backprop through\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# the proposals\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m proposals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbox_coder\u001b[39m.\u001b[39;49mdecode(pred_bbox_deltas\u001b[39m.\u001b[39;49mdetach(), anchors)\n\u001b[1;32m    371\u001b[0m proposals \u001b[39m=\u001b[39m proposals\u001b[39m.\u001b[39mview(num_images, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[1;32m    372\u001b[0m boxes, scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_proposals(proposals, objectness, images\u001b[39m.\u001b[39mimage_sizes, num_anchors_per_level)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torchvision/models/detection/_utils.py:178\u001b[0m, in \u001b[0;36mBoxCoder.decode\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m box_sum \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    177\u001b[0m     rel_codes \u001b[39m=\u001b[39m rel_codes\u001b[39m.\u001b[39mreshape(box_sum, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m pred_boxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecode_single(rel_codes, concat_boxes)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m box_sum \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     pred_boxes \u001b[39m=\u001b[39m pred_boxes\u001b[39m.\u001b[39mreshape(box_sum, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/torchvision/models/detection/_utils.py:216\u001b[0m, in \u001b[0;36mBoxCoder.decode_single\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    213\u001b[0m pred_h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(dh) \u001b[39m*\u001b[39m heights[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    215\u001b[0m \u001b[39m# Distance from center to box's corner.\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m c_to_c_h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m0.5\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mpred_ctr_y\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49mpred_h\u001b[39m.\u001b[39;49mdevice) \u001b[39m*\u001b[39m pred_h\n\u001b[1;32m    217\u001b[0m c_to_c_w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.5\u001b[39m, dtype\u001b[39m=\u001b[39mpred_ctr_x\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mpred_w\u001b[39m.\u001b[39mdevice) \u001b[39m*\u001b[39m pred_w\n\u001b[1;32m    219\u001b[0m pred_boxes1 \u001b[39m=\u001b[39m pred_ctr_x \u001b[39m-\u001b[39m c_to_c_w\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "all_imgs = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/image/*.png'))\n",
    "all_masks = sorted(glob.glob('/home/viktor/Documents/kaggle/hubmap-2023/experiments/mask-rcnn/new-dataset/train/mask/*.png'))\n",
    "all_imgs = np.array(all_imgs)\n",
    "all_masks = np.array(all_masks)\n",
    "train_img = all_imgs[train_index]\n",
    "train_mask = all_masks[train_index]\n",
    "val_img = all_imgs[test_index]\n",
    "val_mask = all_masks[test_index]\n",
    "dataset_train = PennFudanDataset(train_img, train_mask, 'train')\n",
    "dataset_val = PennFudanDataset(val_img, val_mask, 'test')\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=4, shuffle=True, num_workers=os.cpu_count(), pin_memory=True, drop_last=True, collate_fn=utils.collate_fn)\n",
    "val_dl = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=os.cpu_count(), pin_memory=True,collate_fn=utils.collate_fn)\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes=2)\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=1e-6)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# set linear warmup scheduler, with constant learning rate after warmup\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0001,\n",
    "                                            steps_per_epoch=10, epochs=20,\n",
    "                                            pct_start=0.01)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_one_epoch(model, optimizer, train_dl, device, epoch, print_freq=50)\n",
    "    evaluate(model, val_dl, device=device)\n",
    "    scheduler.step()\n",
    "    model_path = f'ckpts/fold_{0}_epoch{epoch}.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
