{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73dea9ca",
   "metadata": {
    "papermill": {
     "duration": 0.006587,
     "end_time": "2023-04-08T10:11:36.662576",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.655989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HubMap Training Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdbb7ff",
   "metadata": {
    "papermill": {
     "duration": 0.004951,
     "end_time": "2023-04-08T10:11:36.672955",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.668004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d956f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:37.772587Z",
     "iopub.status.busy": "2023-05-23T07:55:37.772196Z",
     "iopub.status.idle": "2023-05-23T07:55:38.544450Z",
     "shell.execute_reply": "2023-05-23T07:55:38.544010Z"
    },
    "papermill": {
     "duration": 3.289261,
     "end_time": "2023-04-08T10:12:09.273534",
     "exception": false,
     "start_time": "2023-04-08T10:12:05.984273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b00fe4",
   "metadata": {
    "papermill": {
     "duration": 0.007297,
     "end_time": "2023-04-08T10:12:09.288770",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.281473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e26b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:38.546316Z",
     "iopub.status.busy": "2023-05-23T07:55:38.546120Z",
     "iopub.status.idle": "2023-05-23T07:55:38.548254Z",
     "shell.execute_reply": "2023-05-23T07:55:38.547940Z"
    },
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-04-08T10:12:09.312935",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.296364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LR = 3e-5\n",
    "    EPOCHS = 200\n",
    "    BATCH_SIZE = 12\n",
    "    N_TRAIN = 1400 # Take first N_TRAIN images for training, rest for validation\n",
    "\n",
    "     \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff9cd3e8",
   "metadata": {
    "papermill": {
     "duration": 0.008474,
     "end_time": "2023-04-08T10:12:11.580070",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.571596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0c6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:38.792019Z",
     "iopub.status.busy": "2023-05-23T07:55:38.791912Z",
     "iopub.status.idle": "2023-05-23T07:55:39.087572Z",
     "shell.execute_reply": "2023-05-23T07:55:39.087228Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "from PIL import Image\n",
    "from skimage.draw import polygon\n",
    "from albumentations import Compose, Resize, HorizontalFlip, VerticalFlip, BboxParams\n",
    "\n",
    "\n",
    "\n",
    "class HubmapDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, image_dir, labels_file, n_train, mode='train'):\n",
    "        \n",
    "        assert mode in ['train', 'val'], \"mode must be one of ['train', 'val']\"\n",
    "        self.mode = mode\n",
    "        \n",
    "        with open(labels_file, 'r') as json_file:\n",
    "            self.json_labels = [json.loads(line) for line in json_file]\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.json_labels = self.json_labels[:n_train]\n",
    "        else:\n",
    "            self.json_labels = self.json_labels[n_train:]\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        \n",
    "        if mode == 'train':\n",
    "            initial_augm = [\n",
    "            \n",
    "                \n",
    "                A.HorizontalFlip(p=0.25),\n",
    "                A.VerticalFlip(p=0.25),\n",
    "                A.Transpose(p=0.25),\n",
    "                A.GridDistortion(p=0.25),\n",
    "                A.CoarseDropout(max_holes=1, max_width=int(512 * 0.05), max_height=int(512 * 0.05), \n",
    "                                mask_fill_value=0, p=0.2),\n",
    "                A.RandomSizedCrop(min_max_height=(384, 512),\n",
    "                                    height=512, width=512, p=0.1),\n",
    "                \n",
    "                \n",
    "                A.CLAHE(p=0.2),\n",
    "                A.RandomBrightnessContrast(p=0.2),    \n",
    "                A.RandomGamma(p=0.2),\n",
    "                \n",
    "                A.OneOf([\n",
    "                        A.GaussNoise(var_limit=[10, 50]),\n",
    "                        A.GaussianBlur(),\n",
    "                        A.MotionBlur(),\n",
    "                        ], p=0.1),\n",
    "                A.MultiplicativeNoise(per_channel=True, multiplier=(0.95, 1.05), p=0.2),\n",
    "                \n",
    "            ]\n",
    "        else:\n",
    "            initial_augm = []\n",
    "        \n",
    "        self.aug_list = initial_augm + [\n",
    "                A.Resize(512, 512),\n",
    "                A.Normalize(\n",
    "                    mean= [0, 0, 0],\n",
    "                    std= [1, 1, 1],\n",
    "                    max_pixel_value = 255\n",
    "                ),\n",
    "                ToTensorV2(transpose_mask=True),\n",
    "            ]\n",
    "        \n",
    "        # Create the augmentation pipeline\n",
    "        self.augmentations = A.Compose(self.aug_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.json_labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_path = os.path.join(self.image_dir, f\"{self.json_labels[idx]['id']}.tif\")\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        \n",
    "        # Get the mask\n",
    "        mask = np.zeros((512, 512), dtype=np.float32)\n",
    "        \n",
    "        for annot in self.json_labels[idx]['annotations']:\n",
    "            cords = annot['coordinates']\n",
    "            if annot['type'] == \"blood_vessel\":\n",
    "                for cord in cords:\n",
    "                    rr, cc = polygon(np.array([i[1] for i in cord]), np.asarray([i[0] for i in cord]))\n",
    "                    mask[rr, cc] = 1\n",
    "                    \n",
    "        image = np.array(image)\n",
    "\n",
    "        # image = torch.tensor(np.array(image), dtype=torch.float32).permute(2, 0, 1)  # Shape: [C, H, W]\n",
    "        # mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        augmented = self.augmentations(image=image, mask=mask)\n",
    "        image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "        \n",
    "        \n",
    "        mean = torch.mean(image, dim=[1,2])\n",
    "        std = torch.std(image, dim=[1,2])\n",
    "        \n",
    "        image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "        \n",
    "        # Take random crop of size 384x384\n",
    "        x_start = random.randint(0, 512 - 384)\n",
    "        y_start = random.randint(0, 512 - 384)\n",
    "        image = image[:, x_start:x_start+384, y_start:y_start+384]\n",
    "        mask = mask[x_start:x_start+384, y_start:y_start+384]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HubmapDataset(image_dir=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/train\", \n",
    "                              labels_file=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/polygons.jsonl\", \n",
    "                              n_train=CFG.N_TRAIN,\n",
    "                              mode='train')\n",
    "\n",
    "val_dataset = HubmapDataset(image_dir=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/train\", \n",
    "                              labels_file=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/polygons.jsonl\", \n",
    "                              n_train=CFG.N_TRAIN,\n",
    "                              mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "\n",
    "indx = np.random.randint(0, len(train_dataset))\n",
    "image, mask = train_dataset[indx]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(0.5 * image.permute(1, 2, 0)[:, :, 0] + 0.6 * mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_dataset)\n",
    "n_val = len(val_dataset)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, num_workers=1,\n",
    "                              shuffle=True, pin_memory=False, drop_last=True)\n",
    "\n",
    "dataloader_valid = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, num_workers=1,\n",
    "                              shuffle=False, pin_memory=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78815714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one batch from dataloader_train\n",
    "\n",
    "for batch in dataloader_train:\n",
    "    images, masks = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ef93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def seg_to_det(\n",
    "    seg: np.ndarray, \n",
    "    seg_thresh: float\n",
    "):\n",
    "    num_outputs, labels, stats, centroids = cv2.connectedComponentsWithStats((seg > seg_thresh).astype(np.uint8)*255, 8)\n",
    "    boxes = stats[:, [cv2.CC_STAT_LEFT, cv2.CC_STAT_TOP, cv2.CC_STAT_WIDTH, cv2.CC_STAT_HEIGHT]]\n",
    "    label_masks = [labels == i for i in range(num_outputs)]\n",
    "    dets = {\n",
    "        \"boxes\": np.stack([\n",
    "            boxes[:, 0],\n",
    "            boxes[:, 1],\n",
    "            boxes[:, 0] + boxes[:, 2],\n",
    "            boxes[:, 1] + boxes[:, 3],\n",
    "        ], axis=1),\n",
    "        \"masks\": [seg * m for m in label_masks],\n",
    "    }\n",
    "    dets[\"scores\"] = [np.mean(seg[m]) for m in label_masks]\n",
    "    \n",
    "    # remove dets element where 'boxes' = [0, 0, 512, 512]\n",
    "    boxes_to_remove = [0, 0, 512, 512]\n",
    "    indices_to_remove = np.where(np.all(dets[\"boxes\"] == boxes_to_remove, axis=1))\n",
    "    \n",
    "    dets[\"boxes\"] = np.delete(dets[\"boxes\"], indices_to_remove, axis=0)\n",
    "    dets[\"masks\"] = [i for j, i in enumerate(dets[\"masks\"]) if j not in indices_to_remove]\n",
    "    dets[\"scores\"] = np.delete(dets[\"scores\"], indices_to_remove)\n",
    "    \n",
    "    return dets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2004ef6",
   "metadata": {},
   "source": [
    "# Competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57310709",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30046640",
   "metadata": {},
   "source": [
    "# FBeta metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "def fbeta_score(preds, targets, threshold, beta=1.0, smooth=1e-5):\n",
    "    preds_t = torch.where(preds > threshold, 1.0, 0.0).float()\n",
    "    y_true_count = targets.sum()\n",
    "    \n",
    "    ctp = preds_t[targets==1].sum()\n",
    "    cfp = preds_t[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2272238",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "import torch\n",
    "\n",
    "class Segformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seg_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b5\",\n",
    "                                                         num_labels=1,\n",
    "                                                         ignore_mismatched_sizes=True,\n",
    "                                                         num_channels=3)\n",
    "        self.up = nn.Upsample(scale_factor=4, mode=\"bilinear\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.seg_model(x).logits\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = Segformer().to(CFG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64525439",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 128, 128).to(CFG.device)\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c37663",
   "metadata": {},
   "source": [
    "# Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "DiceLoss = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss(pos_weight=torch.tensor(1.0).to(CFG.device))\n",
    "FocalLoss = smp.losses.FocalLoss(mode='binary')\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    \n",
    "    \n",
    "    return BCELoss(y_pred, y_true)\n",
    "    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n",
    "    \n",
    "    \n",
    "    # return FocalLoss(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AdamW optimizer \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, \n",
    "                                              start_factor=0.001,\n",
    "                                              end_factor=1,\n",
    "                                              total_iters=30)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd729d3e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fbeta_ = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(1, CFG.EPOCHS+1):\n",
    "    model.train()\n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    pbar_train = enumerate(dataloader_train)\n",
    "    pbar_train = tqdm(pbar_train, total=len(dataloader_train), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    \n",
    "    mloss_train = 0.\n",
    "\n",
    "    for i, (images, masks) in pbar_train:\n",
    "        images, masks = images.to(CFG.device), masks.to(CFG.device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_masks = model(images)\n",
    "        loss = criterion(pred_masks.squeeze(), masks)\n",
    "        loss.backward()\n",
    "        mloss_train += loss.detach().item()\n",
    "        optimizer.step()\n",
    "\n",
    "        gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
    "        pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{CFG.EPOCHS}\", gpu_mem, cur_lr,\n",
    "                                                              f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
    "        \n",
    "        # if i > 10:\n",
    "        #     break\n",
    "    \n",
    "    \n",
    "    out = {}\n",
    "    out['epoch'] = epoch\n",
    "    out['loss_train'] = mloss_train / len(dataloader_train)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    pbar_val = enumerate(dataloader_valid)\n",
    "    pbar_val = tqdm(pbar_val, total=len(dataloader_valid), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    \n",
    "    mloss_val = 0.\n",
    "    \n",
    "    \n",
    "    best_th     = 0.0\n",
    "    best_fbeta  = 0.0\n",
    "    \n",
    "    th_array = np.arange(0.01, 1.00, 0.01)\n",
    "    \n",
    "    y_true_count = 0\n",
    "    ctp = {}\n",
    "    cfp = {}\n",
    "    for th in th_array:\n",
    "        ctp[str(th)] = 0\n",
    "        cfp[str(th)] = 0\n",
    "    \n",
    "    for i, (images, masks) in pbar_val:\n",
    "        images, masks = images.to(CFG.device), masks.to(CFG.device)\n",
    "        \n",
    "        masks = masks.squeeze()\n",
    "        with torch.no_grad():\n",
    "            pred_masks = model(images)\n",
    "            mloss_val += criterion(pred_masks.squeeze(), masks).item()\n",
    "            pred_masks = torch.sigmoid(pred_masks)\n",
    "            \n",
    "        pred_masks = pred_masks.squeeze()\n",
    "        y_true_count += masks.sum()\n",
    "        \n",
    "        for th in th_array:\n",
    "            preds_t = torch.where(pred_masks > th, 1.0, 0.0).float()\n",
    "            cfp[str(th)] += preds_t[masks==0].sum()\n",
    "            ctp[str(th)] += preds_t[masks==1].sum()\n",
    "        \n",
    "        pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
    "    \n",
    "    \n",
    "    c_precision = {}\n",
    "    c_recall = {}\n",
    "    dice = {}\n",
    "    \n",
    "    for th in th_array:\n",
    "        c_precision[str(th)] = ctp[str(th)] / (ctp[str(th)] + cfp[str(th)] + 1e-5)\n",
    "        c_recall[str(th)] = ctp[str(th)] / (y_true_count + 1e-5)\n",
    "        dice[str(th)] = (1 + 1) * (c_precision[str(th)] * c_recall[str(th)]) / (1 * c_precision[str(th)] + c_recall[str(th)] + 1e-5)\n",
    "    \n",
    "    \n",
    "    # find the best threshold\n",
    "    best_fbeta = 0\n",
    "    for th in th_array:\n",
    "        if dice[str(th)] > best_fbeta:\n",
    "            best_fbeta = dice[str(th)].item()\n",
    "            best_th = th\n",
    "    \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    out['loss_val'] = mloss_val / len(dataloader_valid)\n",
    "    out['th_best'] = best_th \n",
    "    out['best_fbeta'] = best_fbeta \n",
    "    \n",
    "    \n",
    "    # save out to csv. Rewrite every epoch\n",
    "    if epoch == 1:\n",
    "        df = pd.DataFrame(out, index=[0])\n",
    "        df.to_csv(\"./segformer.csv\", index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(out, index=[0])\n",
    "        df_old = pd.read_csv(\"./segformer.csv\")\n",
    "        df = pd.concat([df_old, df], axis=0)\n",
    "        df.to_csv(\"./segformer.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f\"./ckpts/segformer_epoch_{epoch}.pt\")\n",
    "    \n",
    "    \n",
    "    # empty memory\n",
    "    del images, masks, pred_masks\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795cfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4132.646938,
   "end_time": "2023-04-08T11:20:18.816611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-08T10:11:26.169673",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
