{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### YOLO v8 train & inference\n","\n","We use the YOLO V8 model for this competition because it can execute the object detection and segmentation at the same time.  \n","Because of this notebook is online, we can't submit this directly.  "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-29T05:41:18.390368Z","iopub.status.busy":"2023-05-29T05:41:18.389846Z","iopub.status.idle":"2023-05-29T05:41:18.415634Z","shell.execute_reply":"2023-05-29T05:41:18.414445Z","shell.execute_reply.started":"2023-05-29T05:41:18.390325Z"},"trusted":true},"outputs":[],"source":["import shutil\n","import os\n","import pandas as pd\n","import numpy as np\n","import tifffile as tiff\n","import matplotlib.pyplot as plt\n","\n","from pathlib import Path\n","from glob import glob\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","from IPython.display import Image as show_image\n","\n","import ultralytics\n","from ultralytics import YOLO\n","\n","import torch\n","\n","ultralytics.checks()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Set parameters"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Hyper parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.011600Z","iopub.status.busy":"2023-05-29T05:14:39.011051Z","iopub.status.idle":"2023-05-29T05:14:39.021196Z","shell.execute_reply":"2023-05-29T05:14:39.020040Z","shell.execute_reply.started":"2023-05-29T05:14:39.011570Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","IMAGE_SIZE = 512\n","BATCH_SIZE = 16\n","EPOCHS = 400\n","\n","# File path settings\n","# BASE_DIR = Path('/kaggle/input/hubmap-hacking-the-human-vasculature')\n","BASE_DIR = Path('/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data')\n","\n","print(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.026258Z","iopub.status.busy":"2023-05-29T05:14:39.025445Z","iopub.status.idle":"2023-05-29T05:14:39.035160Z","shell.execute_reply":"2023-05-29T05:14:39.033936Z","shell.execute_reply.started":"2023-05-29T05:14:39.026229Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def mkdir_yolo_data(train_path, val_path):\n","    \"\"\"\n","    make yolo data's directories\n","    \n","    parameters\n","    ----------\n","    train_path: str\n","        path for training data\n","    val_path: str\n","        path for validation data\n","    \n","    returns\n","    ----------\n","    train_image_path: str\n","        path for images of training data\n","    train_label_path: str\n","        path for labels of trainingdata\n","    val_image_path: str\n","        path for images of validation data\n","    val_label_path: str\n","        path for labels of validation data\n","    \"\"\"\n","    train_image_path = Path(f'{train_path}/images')\n","    train_label_path = Path(f'{train_path}/labels')\n","    val_image_path = Path(f'{val_path}/images')\n","    val_label_path = Path(f'{val_path}/labels')\n","    \n","    train_image_path.mkdir(parents=True, exist_ok=True)\n","    train_label_path.mkdir(parents=True, exist_ok=True)\n","    val_image_path.mkdir(parents=True, exist_ok=True)\n","    val_label_path.mkdir(parents=True, exist_ok=True)\n","    \n","    return train_image_path, train_label_path, val_image_path, val_label_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.036807Z","iopub.status.busy":"2023-05-29T05:14:39.036457Z","iopub.status.idle":"2023-05-29T05:14:39.054896Z","shell.execute_reply":"2023-05-29T05:14:39.053520Z","shell.execute_reply.started":"2023-05-29T05:14:39.036780Z"},"trusted":true},"outputs":[],"source":["\n","\n","test_paths = glob(f'{BASE_DIR}/test/*')\n","polygons_path = f'{BASE_DIR}/polygons.jsonl'\n","\n","yolo_train_path = 'datasets/train'\n","yolo_val_path = 'datasets/val'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.057782Z","iopub.status.busy":"2023-05-29T05:14:39.056663Z","iopub.status.idle":"2023-05-29T05:14:39.065358Z","shell.execute_reply":"2023-05-29T05:14:39.064036Z","shell.execute_reply.started":"2023-05-29T05:14:39.057742Z"},"trusted":true},"outputs":[],"source":["# make directories\n","train_image_path, train_label_path, val_image_path, val_label_path = mkdir_yolo_data(yolo_train_path, yolo_val_path)\n","print(train_image_path)\n","print(train_label_path)\n","print(val_image_path)\n","print(val_label_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create annotation files and move tif to yolo' directory"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.068369Z","iopub.status.busy":"2023-05-29T05:14:39.067468Z","iopub.status.idle":"2023-05-29T05:14:39.086640Z","shell.execute_reply":"2023-05-29T05:14:39.085393Z","shell.execute_reply.started":"2023-05-29T05:14:39.068331Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_vessel_annotations(polygons_path):\n","    \"\"\"\n","    Create annotations set which have blood_vessel label.\n","    \n","    parameters\n","    ----------\n","    polygons_path: str\n","        path of polygons.jsonl\n","    \n","    returns\n","    ----------\n","    annotations_dict: dict {key=id, value=coordinates}\n","        annotations dict with key id and value coordinates of blood_vessel\n","    \"\"\"\n","    # load polygons data\n","    polygons = pd.read_json(polygons_path, orient='records', lines=True)\n","    \n","    # extract blood_vessel annotation\n","    annotations_dict = defaultdict(list)\n","    for idx, row in polygons.iterrows():\n","        id_ = row['id']\n","        annotations = row['annotations']\n","        for annotation in annotations:\n","            if annotation['type'] == 'blood_vessel':\n","                annotations_dict[id_].append(annotation['coordinates'])\n","    \n","    return annotations_dict\n","\n","def create_label_file(id_, coordinates, path):\n","    \"\"\"\n","    Create label txt file for yolo v8\n","    \n","    parameters\n","    ----------\n","    id_: str\n","        label id\n","    coordinates: list\n","        coordinates of blood_vessel\n","    path: str\n","        path for saving label txt file\n","    \"\"\"\n","    label_txt = ''\n","    for coordinate in coordinates:\n","        label_txt += '0 '\n","        # Normalize\n","        coor_array = np.array(coordinate[0]).astype(float)\n","        coor_array /= float(IMAGE_SIZE)\n","        # transform to str\n","        coor_list = list(coor_array.reshape(-1).astype(str))\n","        coor_str = ' '.join(coor_list)\n","        # add string to label txt\n","        label_txt += f'{coor_str}\\n'\n","    \n","    # Write labels to txt file\n","    with open(f'{path}/{id_}.txt', 'w') as f:\n","        f.write(label_txt)\n","        \n","def prepare_yolo_dataset(\n","        annotaions_dict, train_image_path, train_label_path, \n","        val_image_path, val_label_path):\n","    \"\"\"\n","    Prepare yolo dataset with images and labels\n","    \n","    parameters\n","    ----------\n","    annotations_dict: dict {key=id, value=coordinates}\n","        annotations dict with key id and value coordinates of blood_vessel\n","    train_image_path: str\n","        path for images of training data\n","    train_label_path: str\n","        path for labels of trainingdata\n","    val_image_path: str\n","        path for images of validation data\n","    val_label_path: str\n","        path for labels of validation data\n","    \"\"\"\n","    ids = list(annotations_dict.keys())\n","    \n","    # train test split\n","    indices = [i for i in range(len(ids))]\n","    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=1234)\n","    \n","    # Training data\n","    for index in tqdm(train_indices):\n","        id_ = ids[index]\n","        \n","        # create label txt file\n","        create_label_file(id_, annotations_dict[id_], train_label_path)\n","        # copy tif image file to yolo directory\n","        source_file = f'{BASE_DIR}/train/{id_}.tif'\n","        shutil.copy2(source_file, train_image_path)\n","    \n","    # Validation data\n","    for index in tqdm(val_indices):\n","        id_ = ids[index]\n","        \n","        # create label txt file\n","        create_label_file(id_, annotations_dict[id_], val_label_path)\n","        # copy tif image file to yolo directory\n","        source_file = f'{BASE_DIR}/train/{id_}.tif'\n","        shutil.copy2(source_file, val_image_path)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:39.089394Z","iopub.status.busy":"2023-05-29T05:14:39.088572Z","iopub.status.idle":"2023-05-29T05:14:44.171277Z","shell.execute_reply":"2023-05-29T05:14:44.170194Z","shell.execute_reply.started":"2023-05-29T05:14:39.089352Z"},"trusted":true},"outputs":[],"source":["# Create annotations dict with key=id and value=coordinates\n","annotations_dict = create_vessel_annotations(polygons_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T05:14:44.173409Z","iopub.status.busy":"2023-05-29T05:14:44.173001Z","iopub.status.idle":"2023-05-29T05:15:19.950275Z","shell.execute_reply":"2023-05-29T05:15:19.948610Z","shell.execute_reply.started":"2023-05-29T05:14:44.173372Z"},"trusted":true},"outputs":[],"source":["# Prepare dataset for yolo training\n","prepare_yolo_dataset(\n","    annotations_dict, train_image_path, train_label_path,\n","    val_image_path, val_label_path\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
