{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73dea9ca",
   "metadata": {
    "papermill": {
     "duration": 0.006587,
     "end_time": "2023-04-08T10:11:36.662576",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.655989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HubMap Training Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdbb7ff",
   "metadata": {
    "papermill": {
     "duration": 0.004951,
     "end_time": "2023-04-08T10:11:36.672955",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.668004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d956f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:37.772587Z",
     "iopub.status.busy": "2023-05-23T07:55:37.772196Z",
     "iopub.status.idle": "2023-05-23T07:55:38.544450Z",
     "shell.execute_reply": "2023-05-23T07:55:38.544010Z"
    },
    "papermill": {
     "duration": 3.289261,
     "end_time": "2023-04-08T10:12:09.273534",
     "exception": false,
     "start_time": "2023-04-08T10:12:05.984273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b00fe4",
   "metadata": {
    "papermill": {
     "duration": 0.007297,
     "end_time": "2023-04-08T10:12:09.288770",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.281473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e26b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:38.546316Z",
     "iopub.status.busy": "2023-05-23T07:55:38.546120Z",
     "iopub.status.idle": "2023-05-23T07:55:38.548254Z",
     "shell.execute_reply": "2023-05-23T07:55:38.547940Z"
    },
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-04-08T10:12:09.312935",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.296364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LR = 1e-4\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "    N_TRAIN = 1400 # Take first N_TRAIN images for training, rest for validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff9cd3e8",
   "metadata": {
    "papermill": {
     "duration": 0.008474,
     "end_time": "2023-04-08T10:12:11.580070",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.571596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0c6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:55:38.792019Z",
     "iopub.status.busy": "2023-05-23T07:55:38.791912Z",
     "iopub.status.idle": "2023-05-23T07:55:39.087572Z",
     "shell.execute_reply": "2023-05-23T07:55:39.087228Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "from PIL import Image\n",
    "from skimage.draw import polygon\n",
    "from albumentations import Compose, Resize, HorizontalFlip, VerticalFlip, BboxParams\n",
    "\n",
    "\n",
    "\n",
    "class HubmapDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, image_dir, labels_file, n_train, mode='train'):\n",
    "        \n",
    "        assert mode in ['train', 'val'], \"mode must be one of ['train', 'val']\"\n",
    "        self.mode = mode\n",
    "        \n",
    "        with open(labels_file, 'r') as json_file:\n",
    "            self.json_labels = [json.loads(line) for line in json_file]\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.json_labels = self.json_labels[:n_train]\n",
    "        else:\n",
    "            self.json_labels = self.json_labels[n_train:]\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        \n",
    "        if mode == 'train':\n",
    "            initial_augm = [\n",
    "            \n",
    "                \n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                \n",
    "                A.RandomBrightnessContrast(p=0.75),\n",
    "                # A.CoarseDropout(max_holes=1, max_width=int(512 * 0.1), max_height=int(512 * 0.1), \n",
    "                                # mask_fill_value=0, p=0.5),\n",
    "                \n",
    "                \n",
    "                A.OneOf([\n",
    "                        A.GaussNoise(var_limit=[0.01, 0.05]),\n",
    "                        A.GaussianBlur(blur_limit=(3, 5), sigma_limit=0),\n",
    "                        A.MotionBlur(blur_limit=3),\n",
    "                        ], p=0.4),\n",
    "                A.MultiplicativeNoise(per_channel=True, multiplier=(0.95, 1.05)),\n",
    "                \n",
    "                \n",
    "            ]\n",
    "        else:\n",
    "            initial_augm = []\n",
    "        \n",
    "        self.aug_list = initial_augm + [\n",
    "                A.Resize(512, 512),\n",
    "                A.Normalize(\n",
    "                    mean= [0, 0, 0],\n",
    "                    std= [1, 1, 1],\n",
    "                    max_pixel_value = 255\n",
    "                ),\n",
    "                ToTensorV2(transpose_mask=True),\n",
    "            ]\n",
    "        \n",
    "        # Create the augmentation pipeline\n",
    "        self.augmentations = A.Compose(self.aug_list, bbox_params=BboxParams(format='pascal_voc'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.json_labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_path = os.path.join(self.image_dir, f\"{self.json_labels[idx]['id']}.tif\")\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        \n",
    "        # Get the mask\n",
    "        mask = np.zeros((512, 512), dtype=np.float32)\n",
    "        bounding_boxes = []\n",
    "        \n",
    "        for annot in self.json_labels[idx]['annotations']:\n",
    "            cords = annot['coordinates']\n",
    "            if annot['type'] == \"blood_vessel\":\n",
    "                for cord in cords:\n",
    "                    rr, cc = polygon(np.array([i[1] for i in cord]), np.asarray([i[0] for i in cord]))\n",
    "                    mask[rr, cc] = 1\n",
    "                    \n",
    "                    # compute bounding box\n",
    "                    x_min = np.min(np.array([i[0] for i in cord]))\n",
    "                    x_max = np.max(np.array([i[0] for i in cord]))\n",
    "                    y_min = np.min(np.array([i[1] for i in cord]))\n",
    "                    y_max = np.max(np.array([i[1] for i in cord]))\n",
    "                    class_label = 0\n",
    "                    bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "                    \n",
    "        image = np.array(image)\n",
    "\n",
    "        # image = torch.tensor(np.array(image), dtype=torch.float32).permute(2, 0, 1)  # Shape: [C, H, W]\n",
    "        # mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            augmented = self.augmentations(image=image, mask=mask, bboxes=bounding_boxes)\n",
    "            image, mask, bboxes = augmented[\"image\"], augmented[\"mask\"], augmented[\"bboxes\"]\n",
    "            \n",
    "            bboxes = np.array(bboxes)\n",
    "\n",
    "            return image, mask, bboxes\n",
    "        else:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HubmapDataset(image_dir=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/train\", \n",
    "                              labels_file=\"/home/viktor/Documents/kaggle/hubmap-2023/kaggle-data/polygons.jsonl\", \n",
    "                              n_train=CFG.N_TRAIN,\n",
    "                              mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ef93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def seg_to_det(\n",
    "    seg: np.ndarray, \n",
    "    seg_thresh: float\n",
    "):\n",
    "    num_outputs, labels, stats, centroids = cv2.connectedComponentsWithStats((seg > seg_thresh).astype(np.uint8)*255, 8)\n",
    "    boxes = stats[:, [cv2.CC_STAT_LEFT, cv2.CC_STAT_TOP, cv2.CC_STAT_WIDTH, cv2.CC_STAT_HEIGHT]]\n",
    "    label_masks = [labels == i for i in range(num_outputs)]\n",
    "    dets = {\n",
    "        \"boxes\": np.stack([\n",
    "            boxes[:, 0],\n",
    "            boxes[:, 1],\n",
    "            boxes[:, 0] + boxes[:, 2],\n",
    "            boxes[:, 1] + boxes[:, 3],\n",
    "        ], axis=1),\n",
    "        \"masks\": [seg * m for m in label_masks],\n",
    "    }\n",
    "    dets[\"scores\"] = [np.mean(seg[m]) for m in label_masks]\n",
    "    \n",
    "    # remove dets element where 'boxes' = [0, 0, 512, 512]\n",
    "    boxes_to_remove = [0, 0, 512, 512]\n",
    "    indices_to_remove = np.where(np.all(dets[\"boxes\"] == boxes_to_remove, axis=1))\n",
    "    \n",
    "    dets[\"boxes\"] = np.delete(dets[\"boxes\"], indices_to_remove, axis=0)\n",
    "    dets[\"masks\"] = [i for j, i in enumerate(dets[\"masks\"]) if j not in indices_to_remove]\n",
    "    dets[\"scores\"] = np.delete(dets[\"scores\"], indices_to_remove)\n",
    "    \n",
    "    return dets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7eab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "image, mask, bbox = train_dataset[2]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(0.5 * image.permute(1, 2, 0)[:, :, 0] + 0.6 * mask)\n",
    "\n",
    "\n",
    "# draw bounding boxes\n",
    "for box in bbox:\n",
    "    x_min, y_min, x_max, y_max, class_label = box\n",
    "    # plt.plot([x_min, x_max, x_max, x_min, x_min], [y_min, y_min, y_max, y_max, y_min], linewidth=2, color='r')\n",
    "\n",
    "\n",
    "\n",
    "dets = seg_to_det(mask.numpy(), 0.5)\n",
    "bboxes = dets['boxes']\n",
    "\n",
    "# draw bounding boxes\n",
    "for box in bboxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    plt.plot([x_min, x_max, x_max, x_min, x_min], [y_min, y_min, y_max, y_max, y_min], linewidth=2, color='r')\n",
    "\n",
    "\n",
    "\n",
    "# plot together with the original image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2004ef6",
   "metadata": {},
   "source": [
    "# Competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c06df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(pred_box, gt_box):\n",
    "    \"\"\"\n",
    "    Calculate the intersection over union (IoU) between a predicted bounding box and a ground truth bounding box.\n",
    "\n",
    "    Args:\n",
    "        pred_box (list or np.array): Predicted bounding box of format [x1, y1, x2, y2].\n",
    "        gt_box (list or np.array): Ground truth bounding box of format [x1, y1, x2, y2].\n",
    "\n",
    "    Returns:\n",
    "        float: The intersection over union (IoU) between the predicted bounding box and the ground truth bounding box.\n",
    "    \"\"\"\n",
    "    x1_pred, y1_pred, x2_pred, y2_pred = pred_box\n",
    "    x1_gt, y1_gt, x2_gt, y2_gt = gt_box\n",
    "\n",
    "    xi1 = max(x1_pred, x1_gt)\n",
    "    yi1 = max(y1_pred, y1_gt)\n",
    "    xi2 = min(x2_pred, x2_gt)\n",
    "    yi2 = min(y2_pred, y2_gt)\n",
    "\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "\n",
    "    box1_area = (x2_pred - x1_pred) * (y2_pred - y1_pred)\n",
    "    box2_area = (x2_gt - x1_gt) * (y2_gt - y1_gt)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "def calculate_mAP(pred_boxes, gt_boxes, thresh=0.6, scores=None):\n",
    "    \"\"\"\n",
    "    Calculate mAP.\n",
    "\n",
    "    Args:\n",
    "        pred_boxes (np.array): Array of predicted bounding boxes of shape (n_boxes, 4).\n",
    "        gt_boxes (np.array): Array of ground truth bounding boxes of shape (n_boxes, 4).\n",
    "        thresh (float, optional): Threshold value for IoU. Defaults to 0.6.\n",
    "        scores (list or np.array, optional): Array of confidence scores associated with predicted bounding boxes.\n",
    "\n",
    "    Returns:\n",
    "        float: Average precision over all thresholds.\n",
    "        list: List of precision values for each threshold.\n",
    "        list: List of recall values for each threshold.\n",
    "        np.array: Matrix of IoU scores for each pair of predicted and ground truth bounding boxes.\n",
    "    \"\"\"\n",
    "    image_precision = 0.0\n",
    "\n",
    "    # calculate IoUs\n",
    "    ious = np.zeros((len(pred_boxes), len(gt_boxes)))\n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        for j, gt_box in enumerate(gt_boxes):\n",
    "            ious[i, j] = calculate_iou(pred_box, gt_box)\n",
    "\n",
    "    # sort pred_boxes and ious by scores in descending order\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    pred_boxes = pred_boxes[indices]\n",
    "    ious = ious[indices]\n",
    "\n",
    "    gt_match = []\n",
    "    pred_match = []\n",
    "    _gt_match = []\n",
    "    _pred_match = []\n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        matched = False\n",
    "        for j, gt_box in enumerate(gt_boxes):\n",
    "            if ious[i, j] > thresh:\n",
    "                if j not in _gt_match and i not in _pred_match:\n",
    "                    _gt_match.append(j)\n",
    "                    _pred_match.append(i)\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "        if not matched:\n",
    "            _pred_match.append(i)\n",
    "\n",
    "    gt_match.append(_gt_match)\n",
    "    pred_match.append(_pred_match)\n",
    "\n",
    "    n_gt = len(gt_boxes)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for i, _gt_match in enumerate(gt_match):\n",
    "        tp = len(_gt_match)\n",
    "        fp = len(pred_match[i]) - tp\n",
    "        fn = n_gt - tp\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "        image_precision += precision \n",
    "\n",
    "    return image_precision, precisions, recalls, ious\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab251eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "\n",
    "# Your provided data\n",
    "dets = {\n",
    "    'boxes': np.array([[204, 0, 140, 16], [330, 283, 369, 374], [505, 452, 512, 484], [0, 0, 100, 100]], dtype=np.int32),\n",
    "    'scores': np.array([1., 1., 1., 0.9], dtype=np.float32)\n",
    "}\n",
    "\n",
    "\n",
    "gt_boxes = np.array([[331., 284., 369., 374., 0.], [506., 453., 512., 484., 0.], [105., 1., 140., 16., 0.]])\n",
    "\n",
    "# Convert the format of the ground truth boxes to match the format of the predicted boxes\n",
    "gt_boxes = gt_boxes[:, :4]\n",
    "\n",
    "# Calculate AP for a single IoU threshold\n",
    "ap, precisions, recalls, overlaps = calculate_mAP(dets['boxes'], gt_boxes, thresh=0.6, scores=dets['scores'])\n",
    "\n",
    "print(f\"Average precision: {ap}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30046640",
   "metadata": {},
   "source": [
    "# FBeta metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "def fbeta_score(preds, targets, threshold, beta=1.0, smooth=1e-5):\n",
    "    preds_t = torch.where(preds > threshold, 1.0, 0.0).float()\n",
    "    y_true_count = targets.sum()\n",
    "    \n",
    "    ctp = preds_t[targets==1].sum()\n",
    "    cfp = preds_t[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4132.646938,
   "end_time": "2023-04-08T11:20:18.816611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-08T10:11:26.169673",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
